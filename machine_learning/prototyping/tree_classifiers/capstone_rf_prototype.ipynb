{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Prototype\n",
    "This file uses the insights gathered in the capstone_ml_prototype pipeline to fit a hyperparameter-tuned random forest to the test set to compare accuracy scores across the training and test sets (we use the validation set as the test set, as the test set is not labelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and split the data\n",
    "training_data = pd.read_csv(\"train.csv\")\n",
    "testing_data = pd.read_csv(\"test.csv\")\n",
    "costa_rica_data = training_data.drop(['Target'], axis=1)\n",
    "costa_rica_target = training_data['Target']\n",
    "\n",
    "#Clean the data to either replace or remove string columns\n",
    "costa_rica_data.select_dtypes(exclude=[np.number]).head()\n",
    "costa_rica_data = costa_rica_data.select_dtypes(include=[np.number], exclude=[np.object]).fillna(0)\n",
    "\n",
    "#Split data into 80% train, 20% validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(costa_rica_data.values, costa_rica_target.values, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best criterion:', 'entropy')\n",
      "('Best n_estimators:', 500)\n",
      "('Best max_depth:', 15)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "[ 0.88705882  0.87990581  0.89360031]\n",
      "0.886854982034\n",
      "0.00559261623603\n"
     ]
    }
   ],
   "source": [
    "#Optimize hyperparameters of a DecisionTree model using Grid Search in Python\n",
    "def optimizeParameter(train, test):\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # load libraries\n",
    "    from sklearn import decomposition, datasets\n",
    "    from sklearn import ensemble\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    randomforest = ensemble.RandomForestClassifier()\n",
    "\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a Decision Tree Classifier on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('randomforest', randomforest)])\n",
    "\n",
    "    # Create lists of parameter for Decision Tree Classifier\n",
    "    criterion = ['entropy']\n",
    "    n_estimators=[50, 100, 150, 200, 250, 500, 1000]\n",
    "    #max_depth = [1, 3, 5, 7, 10, 13, 15]\n",
    "    max_depth = [13, 14, 15]\n",
    "    #min_impurity_decrease = [0.23, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    #max_features = [None, 'auto', 'sqrt', 'log2']\n",
    "    #max_leaf_nodes = [None, 10, 20, 30, 40, 100, 200]\n",
    "    #class_weight = [None, 'balanced']\n",
    "    #warm_start = [True, False]\n",
    "    \n",
    "\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__â€™\n",
    "    parameters = dict(randomforest__criterion=criterion,\n",
    "                      randomforest__n_estimators=n_estimators,\n",
    "                      randomforest__max_depth=max_depth)\n",
    "                      #randomforest__min_impurity_decrease=min_impurity_decrease,\n",
    "                      #randomforest__max_features=max_features,\n",
    "                      #randomforest__max_leaf_nodes=max_leaf_nodes,\n",
    "                      #randomforest__class_weight=class_weight)\n",
    "                      #randomforest__warm_start=warm_start)\n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # View The Best Parameters\n",
    "    print('Best criterion:', clf.best_estimator_.get_params()['randomforest__criterion'])\n",
    "    print('Best n_estimators:', clf.best_estimator_.get_params()['randomforest__n_estimators'])\n",
    "    print('Best max_depth:', clf.best_estimator_.get_params()['randomforest__max_depth'])\n",
    "    #print('Best min_impurity_decrease:', clf.best_estimator_.get_params()['randomforest__min_impurity_decrease'])\n",
    "    #print('Best max_features:', clf.best_estimator_.get_params()['randomforest__max_features'])\n",
    "    #print('Best max_leaf_nodes:', clf.best_estimator_.get_params()['randomforest__max_leaf_nodes'])\n",
    "    #print('Best class_weight:', clf.best_estimator_.get_params()['randomforest__class_weight'])\n",
    "    #print('Best warm_start:', clf.best_estimator_.get_params()['randomforest__warm_start'])\n",
    "    print(clf.best_estimator_.get_params()['randomforest'])\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X_train, y_train, cv=3, n_jobs=1)\n",
    "    print(CV_Result)\n",
    "    print(CV_Result.mean())\n",
    "    print(CV_Result.std())\n",
    "\n",
    "optimizeParameter(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 96.34%\n",
      "Random Forest Test Accuracy: 93.04%\n"
     ]
    }
   ],
   "source": [
    "#Fit a Decision Tree with default parameters to get a baseline idea of performance\n",
    "clf = RandomForestClassifier(random_state=42, n_estimators=500, criterion='entropy', max_depth=15)\n",
    "model = clf.fit(X_train, y_train)\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "print('Random Forest Train Accuracy: '+str(round(train_score*100,2))+'%')\n",
    "print('Random Forest Test Accuracy: '+str(round(test_score*100,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 98 (0.053438)\n",
      "2. feature 135 (0.052117)\n",
      "3. feature 134 (0.035147)\n",
      "4. feature 131 (0.025651)\n",
      "5. feature 118 (0.025495)\n",
      "6. feature 133 (0.025383)\n",
      "7. feature 109 (0.025274)\n",
      "8. feature 132 (0.021411)\n",
      "9. feature 94 (0.020985)\n",
      "10. feature 2 (0.020294)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a forest and compute the feature importances\n",
    "forest = RandomForestClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "n_features = 10\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(n_features):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(n_features), importances[indices][:n_features],\n",
    "       color=\"r\", yerr=std[indices][:n_features], align=\"center\")\n",
    "plt.xticks(range(n_features), indices)\n",
    "plt.xlim([-1, n_features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract feature names\n",
    "cols = costa_rica_data.columns.values\n",
    "dicts = dict(zip(cols, range(len(cols))))\n",
    "\n",
    "features = []\n",
    "for key in dicts:\n",
    "    if dicts[key] in [98, 135, 134, 131, 118, 133, 109, 132, 94, 2]:\n",
    "        features.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Train Accuracy: 96.47%\n",
      "Random Forest Validation Accuracy: 93.36%\n",
      "Train/Test Delta: 3.11%\n"
     ]
    }
   ],
   "source": [
    "#Fit Decision Tree with these most important features\n",
    "X_train, X_test, y_train, y_test = train_test_split(costa_rica_data[features].values, costa_rica_target.values, test_size= 0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=350, criterion='entropy', max_depth=15, random_state=42, max_features=7)\n",
    "model = clf.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "train_score = model.score(X_train, y_train)\n",
    "val_score = model.score(X_test, y_test)\n",
    "print('Random Forest Train Accuracy: '+str(round(train_score*100,2))+'%')\n",
    "print('Random Forest Validation Accuracy: '+str(round(val_score*100,2))+'%')\n",
    "print('Train/Test Delta: '+str(round((train_score - val_score)*100,2))+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results\n",
    "We can see that our model's train and validation accuracy are close together. However, the Random Forest did not perform as strongly as the decision tree. Since our test set does not have labels, we cannot use that to further corroborate our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
